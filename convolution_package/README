步骤如下：

1.编译文件，命令如下
	g++ -o generate_data generate_data.cpp
	nvcc -o convolution convolution.cu

2.修改配置文件Config.txt
	从上到下的数字分别为input_size_x, input_size_y, input_channel, output_channel, Kernel_Size, Strides。
	默认256, 128, 3, 8, 8, 1。

3.生成Input与Kernel数据文件，命令如下
	./generate_data
	其中
	Input.txt储存输入矩阵，存储顺序为input_size_x*input_size_y*input_channel。
	Kernel.txt储存卷积核，存储顺序为kernel_size*kernel_size*input_channel*output_channel。


4.使用CUDA进行卷积，命令如下
	./convolution
	计算结果储存于output_cuda.txt,存储顺序为output_size_x*output_size_y*output_channel。

5.使用PyTorch进行卷积，命令如下
	python torching.py
	计算结果储存于output_torch.txt，存储顺序同上。

6.使用diff比较两个输出文件的结果，命令如下
	python diff.py
	无输出则表明计算结果正确。	
	
	
注意事项：

	1.需说明的是，C语言的float型存储精度有限，在小数点后第5、6位运算时会出现无法避免的浮点误差。而python、pytorch也无法避免浮点误差，在本文件夹中分别使用CUDA、Python、PyTorch实现了卷积操作，三者之间在小数点后第5、6位左右都会出现误差。
	当计算结果过小，以至于低于10^{-2}时，CUDA与PyTorch的当前点结果之间的相对误差就可能高于0.001%（0.00001），我不清楚应用是否能够容忍这样的误差，因为神经网络一般是对微扰较敏感的。
	为了尽量避免这一问题（无法完全避免），可在generate_data.cpp中修改随机数生成范围（第14行的返回范围是[0,10]，第15行的返回范围是[-1,1]，使用时注释掉其中一个即可，注意修改后应重新编译文件并执行），当范围在[0,10]而不是[-1,1]时，出现明显误差的几率便会极大缩小。

	2.在torching.py中，第78行检查Python与PyTorch实现的两种卷积之间的数值差别，可以观察到，即使同在Python环境下，浮点误差仍是无法避免的（假如generate_data.cpp输出的kernel值处于[-1,1]时，该现象更加明显）。
	最终在该文件中，我选择将PyTorch计算得到的结果写入output_torch.txt，可在第89、90行选择写入PyTorch或Python的结果。
