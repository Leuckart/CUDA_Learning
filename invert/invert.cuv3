/**************************************************
	> File Name:  invert.cpp
	> Author:     Leuckart
	> Time:       2018-12-09 19:13
**************************************************/

#include "invert.h"

void Initialize_Matrix(double *mat)
{
	/* should replace by urandom. Leuckart. */
	srand((unsigned)time(0));
	unsigned int mat_size = SIZE * SIZE;

	for (int i = 0; i < mat_size; i++)
	{
		mat[i] = rand() % 100 * 0.01;
	}
}

void Show_Matrix(double *mat, const char *mesg)
{
	cout << mesg << endl;

	unsigned int mat_size = SIZE * SIZE;
	int flag = 0;
	for (int i = 0; i < SIZE; i++)
	{
		for (int j = 0; j < SIZE; j++)
		{
			if (Point(mat, i, j, SIZE) < 0.00001 && Point(mat, i, j, SIZE) > -0.00001)
			{
				cout << "0"
					 << " ";
				//cout << Point(mat, i, j, SIZE) << " ";
			}
			else
			{
				cout << Point(mat, i, j, SIZE) << " ";
			}
			//if(int(Point(mat,i,j,SIZE))!=int((i==j)))
			//	cout<<i<<" "<<j<<" "<<float(Point(mat,i,j,SIZE))<<endl;
			//if (j > 10)
			//	break; //Leuckart
		}
		cout << endl;
		break; //Leuckart.
	}
	cout << endl;
}

__global__ void Row_Kernel_Function(double *ori, double *inv, int now)
{	
	const unsigned int _idx = (blockIdx.x * blockDim.x) + threadIdx.x;
	const unsigned int _idy = (blockIdx.y * blockDim.y) + threadIdx.y;
	const unsigned int thread_idx = ((gridDim.x * blockDim.x) * _idy) + _idx;

	const unsigned int idx = thread_idx / SIZE;
	const unsigned int idy = thread_idx % SIZE;

	if(idx==0&&idy==0)
	{
		double ii = Point(ori, now, now, SIZE);
		double temp = 0.0;
		for (int i = 0; i < SIZE; i++)
		{
			if (i == now)
			{
				continue;
			}
			temp = Point(ori, i, now, SIZE) / ii;
			for (int j = 0; j < SIZE; j++)
			{
				Point(ori, i, j, SIZE) -= Point(ori, now, j, SIZE) * temp;
				Point(inv, i, j, SIZE) -= Point(inv, now, j, SIZE) * temp;
			}
		}
	}
	__syncthreads();

	/*
	if (thread_idx < SIZE * SIZE)
	{
		double ii = Point(ori, now, now, SIZE);
		double temp = 0.0;
		if ((ii < 0.000001) && (ii > -0.000001))
		{
			return;
		}

		if (idx != now)
		{
			temp = Point(ori, idx, now, SIZE) / ii;
			Point(ori, idx, idy, SIZE) -= Point(ori, now, idy, SIZE) * temp;
			Point(inv, idx, idy, SIZE) -= Point(inv, now, idy, SIZE) * temp;
		}
	}
	__syncthreads();
	*/
}

void Row_Function(double *ori, double *inv, int now)
{
	double ii = Point(ori, now, now, SIZE);
	double temp = 0.0;
	for (int i = 0; i < SIZE; i++)
	{
		if (i == now)
		{
			continue;
		}
		temp = Point(ori, i, now, SIZE) / ii;
		for (int j = 0; j < SIZE; j++)
		{
			Point(ori, i, j, SIZE) -= Point(ori, now, j, SIZE) * temp;
			Point(inv, i, j, SIZE) -= Point(inv, now, j, SIZE) * temp;
		}
	}
}

void Inverse_Matrix_Handle(double *ori, double *inv)
{
	//*
	for (int i = 0; i < SIZE; i++)
	{
		Row_Function(ori, inv, i);
		if (i == 115)
			break;
	}
	//*/
	//Row_Function(ori, inv, 116);
}

void Inverse_Matrix_Kernel_Handle(double *ori, double *inv, dim3 Blocks_Per_Grid, dim3 Threads_Per_Block)
{
	//*
	for (int i = 0; i < SIZE; i++)
	{
		Row_Kernel_Function<<<Blocks_Per_Grid, Threads_Per_Block>>>(ori, inv, i);
		cudaThreadSynchronize();
		if (i == 115)
			break;
	}
	//*/
	//Row_Kernel_Function<<<Blocks_Per_Grid, Threads_Per_Block>>>(ori, inv, 116);
	cudaThreadSynchronize();
}

int main()
{
	unsigned int Byte_Size = SIZE * SIZE * sizeof(double);
	double *Matrix_Ori = (double *)malloc(Byte_Size);
	Initialize_Matrix(Matrix_Ori);
	double *Matrix_Inv = (double *)malloc(Byte_Size);

	/* Initial Threads Blocks Begin */
	int thread_xdim = 32;
	int thread_ydim = 32;
	const dim3 Threads_Per_Block(thread_xdim, thread_ydim);
	const dim3 Blocks_Per_Grid(int((SIZE - 1) / Threads_Per_Block.x) + 1, int((SIZE - 1) / Threads_Per_Block.y) + 1);
	/* Initial Threads Blocks End */

	/* Initial Memory Begin */
	double *Matrix_GPU;
	double *Matrix_Inv_GPU;
	double *ident = (double *)malloc(Byte_Size);
	for (int i = 0; i < SIZE; i++)
	{
		Point(ident, i, i, SIZE) = 1;
	}
	Cuda_Call(cudaMalloc((void **)&Matrix_GPU, Byte_Size));
	Cuda_Call(cudaMalloc((void **)&Matrix_Inv_GPU, Byte_Size));
	/* Initial Memory Begin */

	/* Kernel Function Execute Begin */
	Cuda_Call(cudaMemcpy(Matrix_GPU, Matrix_Ori, Byte_Size, cudaMemcpyHostToDevice));
	Cuda_Call(cudaMemcpy(Matrix_Inv_GPU, ident, Byte_Size, cudaMemcpyHostToDevice));
	Inverse_Matrix_Kernel_Handle(Matrix_GPU, Matrix_Inv_GPU, Blocks_Per_Grid, Threads_Per_Block);
	Cuda_Call(cudaMemcpy(Matrix_Inv, Matrix_Inv_GPU, Byte_Size, cudaMemcpyDeviceToHost));
	Show_Matrix(Matrix_Inv, "");

	double *Matrix_Ori_Copy = (double *)malloc(Byte_Size);
	memcpy(Matrix_Ori_Copy, Matrix_Ori, Byte_Size);
	Inverse_Matrix_Handle(Matrix_Ori_Copy, ident);
	Show_Matrix(ident, "");
	/* Kernel Function Execute End */

	/* Copy GPU To CPU Begin */
	//Cuda_Call(cudaMemcpy(Matrix_Ori, Matrix_GPU, Byte_Size, cudaMemcpyDeviceToHost));
	//Show_Matrix(Matrix_Ori,"...");
	/* Copy GPU To CPU End */

	/* Free Memory Begin */
	Cuda_Call(cudaFree(Matrix_GPU));
	free(Matrix_Ori);
	/* Free Memory End */
	return 0;
}
